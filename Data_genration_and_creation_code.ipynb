{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50OPPTlYEbof"
      },
      "outputs": [],
      "source": [
        "dic1 = {\n",
        "    \"name\":\"pratik\",\n",
        "    \"job\":\"python developer\",\n",
        "    \"skill\":[\"python\",\"django\",\"data analysing\"],\n",
        "    \"Exp\":5,\n",
        "    \"currently working\":True\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dic1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHYKfTMgOsZ6",
        "outputId": "76aea500-823f-45b7-def2-7366dbfb19b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dic1.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rvyrMmqQoGJ",
        "outputId": "f5865ecd-1b3d-45fb-f122-0d1aa219d393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['name', 'job', 'skill', 'Exp', 'currently working'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for j in dic1.keys():\n",
        "\n",
        "  if type(dic1[j]) == list:\n",
        "    print(j)\n",
        "    for i in range(len(dic1[j])):\n",
        "\n",
        "      print(f\"({i+1}) {dic1[j][i]}\")\n",
        "  else:\n",
        "\n",
        "    print(f\"{j} : {dic1[j]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otlE-THVN1pH",
        "outputId": "49c252f6-d021-4cc3-9127-f88cd3b20e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name : pratik\n",
            "job : python developer\n",
            "skill\n",
            "(1) python\n",
            "(2) django\n",
            "(3) data analysing\n",
            "Exp : 5\n",
            "currently working : True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "7021015033"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hVBH9bHXk_K",
        "outputId": "f71fd02f-f261-43e7-b607-7237b43459f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7021015033"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i have required skill set of that [\"python\",\"Django\",\"ML\",\"Git\",\"SQL\"] give the matching percentage of job shekkers skill\n",
        "\n",
        "skill_employee = dic1[\"skill\"]\n",
        "required = [\"python\",\"django\",\"ml\",\"git\",\"sql\"]\n",
        "\n",
        "\n",
        "required_match = 0\n",
        "for j in range(len(skill_employee)):\n",
        "\n",
        "  if skill_employee[j].lower() in required:\n",
        "\n",
        "    required_match+=1\n",
        "\n",
        "print(required_match)\n",
        "total_required = len(required)\n",
        "\n",
        "print(f\"Total match skill percentage -: {(required_match/total_required)*100}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h9kJTqbXm0A",
        "outputId": "618108c0-30d6-4250-eccc-8bfa5cb672ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "Total match skill percentage -: 40.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dnc6IKNFdOZR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# 1. Data Generation Functions\n",
        "def generate_stock_data(num_stocks=5, initial_price=100, minutes=10):\n",
        "    \"\"\"Generate simulated real-time stock data\"\"\"\n",
        "    print(\"Generating real-time stock data...\")\n",
        "    price_history = []\n",
        "    current_prices = np.full(num_stocks, initial_price, dtype=np.float64)\n",
        "\n",
        "    for minute in range(minutes):\n",
        "        # Simulate price changes\n",
        "        random_changes = np.random.normal(0, 2, num_stocks)\n",
        "        current_prices += random_changes\n",
        "        current_prices = np.maximum(current_prices, 0.1)\n",
        "\n",
        "        price_history.append(current_prices.copy())\n",
        "\n",
        "        if minute % 2 == 0:\n",
        "            print(f\"Minute {minute}: Prices = {current_prices}\")\n",
        "            print(f\"Average: {np.mean(current_prices):.2f}\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "        time.sleep(0.5)\n",
        "\n",
        "    return np.array(price_history)\n",
        "\n",
        "# 2. Analysis Functions\n",
        "def calculate_basic_stats(prices):\n",
        "    \"\"\"Calculate basic statistics\"\"\"\n",
        "    avg_prices = np.mean(prices, axis=0)\n",
        "    volatility = np.std(prices, axis=0)\n",
        "    highest_prices = np.max(prices, axis=0)\n",
        "    lowest_prices = np.min(prices, axis=0)\n",
        "\n",
        "    return avg_prices, volatility, highest_prices, lowest_prices\n",
        "\n",
        "def calculate_performance_metrics(prices, initial_price):\n",
        "    \"\"\"Calculate performance metrics\"\"\"\n",
        "    price_changes = np.diff(prices, axis=0)\n",
        "    cumulative_returns = np.cumsum(price_changes, axis=0)\n",
        "    final_returns = cumulative_returns[-1] if len(cumulative_returns) > 0 else np.zeros(prices.shape[1])\n",
        "\n",
        "    return price_changes, cumulative_returns, final_returns\n",
        "\n",
        "def find_opportunities(current_prices, avg_prices):\n",
        "    \"\"\"Find trading opportunities\"\"\"\n",
        "    buy_opportunities = np.where(current_prices < avg_prices)[0]\n",
        "    sell_opportunities = np.where(current_prices > avg_prices)[0]\n",
        "\n",
        "    return buy_opportunities, sell_opportunities\n",
        "\n",
        "def analyze_correlations(prices):\n",
        "    \"\"\"Analyze correlations between stocks\"\"\"\n",
        "    return np.corrcoef(prices.T)\n",
        "\n",
        "def calculate_risk_metrics(prices):\n",
        "    \"\"\"Calculate various risk metrics\"\"\"\n",
        "    risk_5th = np.percentile(prices, 5, axis=0)\n",
        "    risk_95th = np.percentile(prices, 95, axis=0)\n",
        "\n",
        "    return risk_5th, risk_95th\n",
        "\n",
        "# 3. Main Analysis Function\n",
        "def analyze_stock_performance(price_data, initial_price=100):\n",
        "    \"\"\"Comprehensive stock performance analysis\"\"\"\n",
        "    if len(price_data) == 0:\n",
        "        print(\"No data available.\")\n",
        "        return\n",
        "\n",
        "    prices = np.array(price_data)\n",
        "    current_prices = prices[-1]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"STOCK PERFORMANCE ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Basic statistics\n",
        "    avg_prices, volatility, highest_prices, lowest_prices = calculate_basic_stats(prices)\n",
        "    print(f\"1. Average prices: {avg_prices}\")\n",
        "    print(f\"2. Volatility: {volatility}\")\n",
        "    print(f\"3. Highest prices: {highest_prices}\")\n",
        "    print(f\"4. Lowest prices: {lowest_prices}\")\n",
        "\n",
        "    # Performance timing\n",
        "    peak_times = np.argmax(prices, axis=0)\n",
        "    trough_times = np.argmin(prices, axis=0)\n",
        "    print(f\"5. Peak times: {peak_times}\")\n",
        "    print(f\"6. Trough times: {trough_times}\")\n",
        "\n",
        "    # Returns analysis\n",
        "    price_changes, cumulative_returns, final_returns = calculate_performance_metrics(prices, initial_price)\n",
        "    print(f\"7. Average daily changes: {np.mean(np.abs(price_changes), axis=0)}\")\n",
        "    print(f\"8. Final returns: {final_returns}\")\n",
        "\n",
        "    # Risk analysis\n",
        "    risk_5th, risk_95th = calculate_risk_metrics(prices)\n",
        "    print(f\"9. 5th percentile risk: {risk_5th}\")\n",
        "    print(f\"10. 95th percentile potential: {risk_95th}\")\n",
        "\n",
        "    # Opportunities\n",
        "    buy_opps, sell_opps = find_opportunities(current_prices, avg_prices)\n",
        "    print(f\"11. Buy opportunities (stocks below avg): {buy_opps}\")\n",
        "    print(f\"12. Sell opportunities (stocks above avg): {sell_opps}\")\n",
        "\n",
        "    # Ranking\n",
        "    performance_ranking = np.argsort(final_returns)[::-1]\n",
        "    sorted_performance = np.sort(final_returns)[::-1]\n",
        "    print(f\"13. Performance ranking: {performance_ranking}\")\n",
        "    print(f\"14. Sorted returns: {sorted_performance}\")\n",
        "\n",
        "    # Correlation\n",
        "    correlation_matrix = analyze_correlations(prices)\n",
        "    print(\"15. Correlation matrix:\")\n",
        "    print(correlation_matrix)\n",
        "\n",
        "    # Additional metrics\n",
        "    distance_from_initial = np.linalg.norm(prices - initial_price, axis=1)\n",
        "    print(f\"16. Avg distance from initial: {np.mean(distance_from_initial):.2f}\")\n",
        "\n",
        "    unique_prices = np.unique(prices.round(1))\n",
        "    print(f\"17. Unique price levels: {len(unique_prices)}\")\n",
        "\n",
        "    # Risk categorization\n",
        "    def risk_category(vol):\n",
        "        if vol < 1: return \"Low\"\n",
        "        elif vol < 2: return \"Medium\"\n",
        "        else: return \"High\"\n",
        "\n",
        "    vectorized_risk = np.vectorize(risk_category)\n",
        "    risk_levels = vectorized_risk(volatility)\n",
        "    print(f\"18. Risk levels: {risk_levels}\")\n",
        "\n",
        "    # Moving average\n",
        "    if len(prices) > 3:\n",
        "        moving_avg = np.convolve(prices[:, 0], np.ones(3)/3, mode='valid')\n",
        "        print(f\"19. Moving average (first stock): {moving_avg[:3]}...\")\n",
        "\n",
        "    # Trend analysis\n",
        "    if len(prices) > 2:\n",
        "        time_points = np.arange(len(prices))\n",
        "        trend = np.polyfit(time_points, prices[:, 0], 1)\n",
        "        print(f\"20. Linear trend: {trend}\")\n",
        "\n",
        "# Run Stock Analyzer\n",
        "def run_stock_analyzer():\n",
        "    \"\"\"Main function to run stock analyzer\"\"\"\n",
        "    print(\"REAL-TIME STOCK ANALYZER\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Generate data\n",
        "    price_data = generate_stock_data(num_stocks=3, initial_price=50, minutes=6)\n",
        "\n",
        "    # Analyze performance\n",
        "    analyze_stock_performance(price_data, initial_price=50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_stock_analyzer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfP-p4ziXybJ",
        "outputId": "bfb170ba-3c8e-43c3-a5f3-c7f20c21b5c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REAL-TIME STOCK ANALYZER\n",
            "==================================================\n",
            "Generating real-time stock data...\n",
            "Minute 0: Prices = [48.62673702 52.91501374 52.26320061]\n",
            "Average: 51.27\n",
            "----------------------------------------\n",
            "Minute 2: Prices = [47.45937322 58.39434115 49.26864808]\n",
            "Average: 51.71\n",
            "----------------------------------------\n",
            "Minute 4: Prices = [46.40167417 58.74941817 47.70544029]\n",
            "Average: 50.95\n",
            "----------------------------------------\n",
            "\n",
            "============================================================\n",
            "STOCK PERFORMANCE ANALYSIS\n",
            "============================================================\n",
            "1. Average prices: [47.92273582 57.48087428 49.78752603]\n",
            "2. Volatility: [1.49876107 2.20959833 1.61789358]\n",
            "3. Highest prices: [49.93785776 59.87225977 52.26320061]\n",
            "4. Lowest prices: [45.80565073 52.91501374 47.70544029]\n",
            "5. Peak times: [5 3 0]\n",
            "6. Trough times: [3 0 4]\n",
            "7. Average daily changes: [1.66201267 1.79504937 1.3765813 ]\n",
            "8. Final returns: [ 1.31112074  4.93924518 -4.17436733]\n",
            "9. 5th percentile risk: [45.95465659 53.96124879 47.80128854]\n",
            "10. 95th percentile potential: [49.77967383 59.59154937 51.98727777]\n",
            "11. Buy opportunities (stocks below avg): [2]\n",
            "12. Sell opportunities (stocks above avg): [0 1]\n",
            "13. Performance ranking: [1 0 2]\n",
            "14. Sorted returns: [ 4.93924518  1.31112074 -4.17436733]\n",
            "15. Correlation matrix:\n",
            "[[ 1.         -0.52360957  0.18330487]\n",
            " [-0.52360957  1.         -0.67576619]\n",
            " [ 0.18330487 -0.67576619  1.        ]]\n",
            "16. Avg distance from initial: 8.09\n",
            "17. Unique price levels: 17\n",
            "18. Risk levels: ['Medium' 'High' 'Medium']\n",
            "19. Moving average (first stock): [48.46374409 47.523382   46.55556604]...\n",
            "20. Linear trend: [-0.10881321 48.19476885]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# ==================== DATA CREATION FUNCTIONS ====================\n",
        "\n",
        "def create_grocery_distributor_data():\n",
        "    \"\"\"Create comprehensive grocery distributor dataset\"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Products data\n",
        "    products = [\n",
        "        'Milk', 'Bread', 'Eggs', 'Rice', 'Pasta', 'Chicken', 'Beef', 'Fish',\n",
        "        'Apples', 'Bananas', 'Oranges', 'Tomatoes', 'Potatoes', 'Onions',\n",
        "        'Cheese', 'Yogurt', 'Butter', 'Cereal', 'Coffee', 'Tea'\n",
        "    ]\n",
        "\n",
        "    categories = ['Dairy', 'Bakery', 'Dairy', 'Grains', 'Grains', 'Meat', 'Meat', 'Seafood',\n",
        "                 'Fruits', 'Fruits', 'Fruits', 'Vegetables', 'Vegetables', 'Vegetables',\n",
        "                 'Dairy', 'Dairy', 'Dairy', 'Breakfast', 'Beverages', 'Beverages']\n",
        "\n",
        "    # Suppliers data\n",
        "    suppliers = ['FreshFarms Inc', 'QualityGoods Co', 'LocalHarvest Ltd',\n",
        "                'PremiumFoods Corp', 'OrganicSuppliers LLC']\n",
        "\n",
        "    # Create products dataframe\n",
        "    products_df = pd.DataFrame({\n",
        "        'product_id': range(1, 21),\n",
        "        'product_name': products,\n",
        "        'category': categories,\n",
        "        'supplier_id': np.random.choice([1, 2, 3, 4, 5], 20),\n",
        "        'cost_price': np.round(np.random.uniform(1, 15, 20), 2),\n",
        "        'selling_price': np.round(np.random.uniform(2, 25, 20), 2),\n",
        "        'safety_stock': np.random.randint(50, 200, 20),\n",
        "        'reorder_point': np.random.randint(20, 100, 20)\n",
        "    })\n",
        "\n",
        "    # Create inventory data\n",
        "    dates = pd.date_range('2024-01-01', '2024-03-31', freq='D')\n",
        "    inventory_data = []\n",
        "\n",
        "    for date in dates:\n",
        "        for product_id in range(1, 21):\n",
        "            inventory_data.append({\n",
        "                'date': date,\n",
        "                'product_id': product_id,\n",
        "                'quantity_in_stock': np.random.randint(0, 500),\n",
        "                'quantity_sold': np.random.randint(0, 100),\n",
        "                'returns': np.random.randint(0, 10)\n",
        "            })\n",
        "\n",
        "    inventory_df = pd.DataFrame(inventory_data)\n",
        "\n",
        "    # Create sales transactions\n",
        "    transactions = []\n",
        "    transaction_id = 1000\n",
        "\n",
        "    for _ in range(1000):\n",
        "        transaction_id += 1\n",
        "        product_id = np.random.randint(1, 21)\n",
        "        product_data = products_df[products_df['product_id'] == product_id].iloc[0]\n",
        "\n",
        "        transactions.append({\n",
        "            'transaction_id': transaction_id,\n",
        "            'date': np.random.choice(dates),\n",
        "            'product_id': product_id,\n",
        "            'quantity': np.random.randint(1, 20),\n",
        "            'customer_id': np.random.randint(1, 51),\n",
        "            'region': np.random.choice(['North', 'South', 'East', 'West']),\n",
        "            'discount': np.random.choice([0, 5, 10, 15], p=[0.6, 0.2, 0.15, 0.05])\n",
        "        })\n",
        "\n",
        "    transactions_df = pd.DataFrame(transactions)\n",
        "\n",
        "    # Create supplier data\n",
        "    supplier_df = pd.DataFrame({\n",
        "        'supplier_id': [1, 2, 3, 4, 5],\n",
        "        'supplier_name': suppliers,\n",
        "        'contact_person': ['John Smith', 'Maria Garcia', 'David Chen', 'Sarah Johnson', 'Mike Brown'],\n",
        "        'email': ['john@freshfarms.com', 'maria@qualitygoods.com',\n",
        "                 'david@localharvest.com', 'sarah@premiumfoods.com', 'mike@organic.com'],\n",
        "        'phone': ['555-0101', '555-0102', '555-0103', '555-0104', '555-0105'],\n",
        "        'reliability_score': np.round(np.random.uniform(3.5, 5.0, 5), 1)\n",
        "    })\n",
        "\n",
        "    return {\n",
        "        'products': products_df,\n",
        "        'inventory': inventory_df,\n",
        "        'transactions': transactions_df,\n",
        "        'suppliers': supplier_df\n",
        "    }\n",
        "\n",
        "# ==================== ADVANCED ANALYSIS FUNCTIONS ====================\n",
        "\n",
        "def calculate_inventory_turnover(data):\n",
        "    \"\"\"Calculate inventory turnover ratio for each product\"\"\"\n",
        "    inventory = data['inventory']\n",
        "    products = data['products']\n",
        "\n",
        "    # Calculate average inventory and total sales\n",
        "    avg_inventory = inventory.groupby('product_id')['quantity_in_stock'].mean()\n",
        "    total_sales = inventory.groupby('product_id')['quantity_sold'].sum()\n",
        "\n",
        "    # Calculate turnover ratio\n",
        "    turnover = total_sales / avg_inventory\n",
        "    turnover_df = turnover.reset_index()\n",
        "    turnover_df.columns = ['product_id', 'turnover_ratio']\n",
        "\n",
        "    # Merge with product names\n",
        "    result = pd.merge(turnover_df, products[['product_id', 'product_name']], on='product_id')\n",
        "    return result.round(3)\n",
        "\n",
        "def analyze_sales_trends(data, window=7):\n",
        "    \"\"\"Analyze sales trends with moving averages\"\"\"\n",
        "    sales_data = data['transactions'].merge(\n",
        "        data['products'][['product_id', 'product_name', 'category']],\n",
        "        on='product_id'\n",
        "    )\n",
        "\n",
        "    daily_sales = sales_data.groupby(['date', 'category'])['quantity'].sum().reset_index()\n",
        "    daily_sales['moving_avg'] = daily_sales.groupby('category')['quantity'].transform(\n",
        "        lambda x: x.rolling(window=window, min_periods=1).mean()\n",
        "    )\n",
        "\n",
        "    return daily_sales\n",
        "\n",
        "def calculate_profit_margins(data):\n",
        "    \"\"\"Calculate profit margins by product and category\"\"\"\n",
        "    transactions = data['transactions']\n",
        "    products = data['products']\n",
        "\n",
        "    # Merge data\n",
        "    merged_data = transactions.merge(products, on='product_id')\n",
        "\n",
        "    # Calculate revenue and cost\n",
        "    merged_data['revenue'] = merged_data['quantity'] * merged_data['selling_price']\n",
        "    merged_data['cost'] = merged_data['quantity'] * merged_data['cost_price']\n",
        "    merged_data['profit'] = merged_data['revenue'] - merged_data['cost']\n",
        "\n",
        "    # Calculate margins\n",
        "    product_margins = merged_data.groupby(['product_id', 'product_name']).agg({\n",
        "        'revenue': 'sum',\n",
        "        'cost': 'sum',\n",
        "        'profit': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    product_margins['profit_margin_pct'] = (product_margins['profit'] / product_margins['revenue']) * 100\n",
        "\n",
        "    return product_margins.round(2)\n",
        "\n",
        "def identify_slow_moving_products(data, threshold_days=30):\n",
        "    \"\"\"Identify slow-moving products based on sales frequency\"\"\"\n",
        "    sales_freq = data['transactions'].groupby('product_id').agg({\n",
        "        'date': ['min', 'max', 'count'],\n",
        "        'quantity': 'sum'\n",
        "    }).reset_index()\n",
        "\n",
        "    sales_freq.columns = ['product_id', 'first_sale', 'last_sale', 'sale_count', 'total_quantity']\n",
        "    sales_freq['days_active'] = (sales_freq['last_sale'] - sales_freq['first_sale']).dt.days + 1\n",
        "    sales_freq['sales_per_day'] = sales_freq['sale_count'] / sales_freq['days_active']\n",
        "\n",
        "    # Fixed: Use proper threshold comparison\n",
        "    threshold_per_day = 1 / threshold_days  # Convert threshold to daily rate\n",
        "    slow_moving = sales_freq[sales_freq['sales_per_day'] < threshold_per_day]\n",
        "\n",
        "    return slow_moving.merge(data['products'][['product_id', 'product_name', 'category']], on='product_id')\n",
        "\n",
        "def calculate_stockout_risk(data):\n",
        "    \"\"\"Calculate stockout risk based on current inventory and sales patterns\"\"\"\n",
        "    inventory = data['inventory']\n",
        "    products = data['products']\n",
        "\n",
        "    # Get latest inventory and sales data\n",
        "    latest_date = inventory['date'].max()\n",
        "    latest_inventory = inventory[inventory['date'] == latest_date]\n",
        "\n",
        "    # Calculate average daily sales\n",
        "    daily_sales = inventory.groupby('product_id')['quantity_sold'].mean().reset_index()\n",
        "    daily_sales.columns = ['product_id', 'avg_daily_sales']\n",
        "\n",
        "    # Merge data\n",
        "    stock_analysis = latest_inventory.merge(daily_sales, on='product_id')\n",
        "    stock_analysis = stock_analysis.merge(products[['product_id', 'product_name', 'safety_stock', 'reorder_point']], on='product_id')\n",
        "\n",
        "    # Calculate days of supply and risk\n",
        "    stock_analysis['days_of_supply'] = stock_analysis['quantity_in_stock'] / stock_analysis['avg_daily_sales']\n",
        "\n",
        "    # Fixed: Use proper string comparison and ensure consistent dtypes\n",
        "    stock_analysis['stockout_risk'] = 'Low'  # Default value\n",
        "    stock_analysis.loc[stock_analysis['days_of_supply'] < 3, 'stockout_risk'] = 'High'\n",
        "    stock_analysis.loc[(stock_analysis['days_of_supply'] >= 3) & (stock_analysis['days_of_supply'] < 7), 'stockout_risk'] = 'Medium'\n",
        "\n",
        "    return stock_analysis[['product_id', 'product_name', 'quantity_in_stock', 'avg_daily_sales',\n",
        "                          'days_of_supply', 'stockout_risk', 'safety_stock', 'reorder_point']]\n",
        "\n",
        "def seasonal_demand_analysis(data):\n",
        "    \"\"\"Analyze seasonal demand patterns by product category\"\"\"\n",
        "    transactions = data['transactions']\n",
        "    products = data['products']\n",
        "\n",
        "    merged_data = transactions.merge(products[['product_id', 'category']], on='product_id')\n",
        "    merged_data['month'] = merged_data['date'].dt.month\n",
        "    merged_data['week'] = merged_data['date'].dt.isocalendar().week\n",
        "\n",
        "    monthly_demand = merged_data.groupby(['month', 'category'])['quantity'].sum().reset_index()\n",
        "    weekly_demand = merged_data.groupby(['week', 'category'])['quantity'].sum().reset_index()\n",
        "\n",
        "    return {\n",
        "        'monthly': monthly_demand,\n",
        "        'weekly': weekly_demand\n",
        "    }\n",
        "\n",
        "def customer_segmentation_analysis(data):\n",
        "    \"\"\"Segment customers based on purchasing behavior\"\"\"\n",
        "    customer_data = data['transactions'].groupby('customer_id').agg({\n",
        "        'transaction_id': 'count',\n",
        "        'quantity': 'sum',\n",
        "        'date': ['min', 'max']\n",
        "    }).reset_index()\n",
        "\n",
        "    customer_data.columns = ['customer_id', 'total_orders', 'total_quantity', 'first_purchase', 'last_purchase']\n",
        "\n",
        "    # Calculate RFM metrics\n",
        "    max_date = data['transactions']['date'].max()\n",
        "    customer_data['recency'] = (max_date - customer_data['last_purchase']).dt.days\n",
        "    customer_data['frequency'] = customer_data['total_orders']\n",
        "\n",
        "    # Fixed: Use proper string assignment with loc\n",
        "    customer_data['segment'] = 'New'  # Default value\n",
        "\n",
        "    # Assign segments using loc to avoid dtype issues\n",
        "    customer_data.loc[(customer_data['recency'] <= 30) & (customer_data['frequency'] >= 5), 'segment'] = 'Loyal'\n",
        "    customer_data.loc[(customer_data['recency'] <= 60) & (customer_data['frequency'] >= 3) &\n",
        "                     (customer_data['segment'] == 'New'), 'segment'] = 'Regular'\n",
        "    customer_data.loc[(customer_data['recency'] <= 90) &\n",
        "                     (customer_data['segment'] == 'New'), 'segment'] = 'Occasional'\n",
        "    customer_data.loc[customer_data['recency'] > 90, 'segment'] = 'Dormant'\n",
        "\n",
        "    return customer_data\n",
        "\n",
        "def supplier_performance_analysis(data):\n",
        "    \"\"\"Analyze supplier performance and reliability\"\"\"\n",
        "    transactions = data['transactions']\n",
        "    products = data['products']\n",
        "    suppliers = data['suppliers']\n",
        "\n",
        "    # Merge all data\n",
        "    merged_data = transactions.merge(products, on='product_id').merge(suppliers, on='supplier_id')\n",
        "\n",
        "    supplier_perf = merged_data.groupby('supplier_id').agg({\n",
        "        'quantity': 'sum',\n",
        "        'transaction_id': 'count',\n",
        "        'product_id': 'nunique',\n",
        "        'reliability_score': 'first'\n",
        "    }).reset_index()\n",
        "\n",
        "    supplier_perf.columns = ['supplier_id', 'total_units_sold', 'total_orders', 'unique_products', 'reliability_score']\n",
        "\n",
        "    # Calculate performance score\n",
        "    supplier_perf['performance_score'] = (\n",
        "        supplier_perf['total_units_sold'] * 0.4 +\n",
        "        supplier_perf['total_orders'] * 0.3 +\n",
        "        supplier_perf['unique_products'] * 0.2 +\n",
        "        supplier_perf['reliability_score'] * 10\n",
        "    )\n",
        "\n",
        "    supplier_perf['performance_rank'] = supplier_perf['performance_score'].rank(ascending=False)\n",
        "\n",
        "    return supplier_perf.merge(suppliers[['supplier_id', 'supplier_name']], on='supplier_id')\n",
        "\n",
        "def regional_sales_analysis(data):\n",
        "    \"\"\"Analyze sales performance by region\"\"\"\n",
        "    transactions = data['transactions']\n",
        "    products = data['products']\n",
        "\n",
        "    merged_data = transactions.merge(products[['product_id', 'category', 'selling_price']], on='product_id')\n",
        "    merged_data['revenue'] = merged_data['quantity'] * merged_data['selling_price']\n",
        "\n",
        "    regional_analysis = merged_data.groupby('region').agg({\n",
        "        'revenue': 'sum',\n",
        "        'quantity': 'sum',\n",
        "        'transaction_id': 'count',\n",
        "        'customer_id': 'nunique'\n",
        "    }).reset_index()\n",
        "\n",
        "    regional_analysis.columns = ['region', 'total_revenue', 'total_quantity', 'total_orders', 'unique_customers']\n",
        "    regional_analysis['avg_order_value'] = regional_analysis['total_revenue'] / regional_analysis['total_orders']\n",
        "\n",
        "    return regional_analysis.round(2)\n",
        "\n",
        "def price_elasticity_analysis(data):\n",
        "    \"\"\"Analyze price elasticity of demand\"\"\"\n",
        "    transactions = data['transactions']\n",
        "    products = data['products']\n",
        "\n",
        "    merged_data = transactions.merge(products[['product_id', 'product_name', 'selling_price']], on='product_id')\n",
        "\n",
        "    # Calculate price and quantity relationships\n",
        "    price_elasticity = merged_data.groupby('product_id').agg({\n",
        "        'selling_price': 'mean',\n",
        "        'quantity': 'sum',\n",
        "        'transaction_id': 'count'\n",
        "    }).reset_index()\n",
        "\n",
        "    price_elasticity.columns = ['product_id', 'avg_price', 'total_quantity', 'transaction_count']\n",
        "\n",
        "    # Simple elasticity calculation (for demonstration)\n",
        "    overall_avg_price = price_elasticity['avg_price'].mean()\n",
        "    overall_avg_quantity = price_elasticity['total_quantity'].mean()\n",
        "\n",
        "    price_elasticity['price_ratio'] = price_elasticity['avg_price'] / overall_avg_price\n",
        "    price_elasticity['quantity_ratio'] = price_elasticity['total_quantity'] / overall_avg_quantity\n",
        "\n",
        "    # Handle division by zero\n",
        "    price_elasticity['elasticity'] = np.where(\n",
        "        price_elasticity['price_ratio'] != 1,\n",
        "        (price_elasticity['quantity_ratio'] - 1) / (price_elasticity['price_ratio'] - 1),\n",
        "        0\n",
        "    )\n",
        "\n",
        "    return price_elasticity.merge(products[['product_id', 'product_name']], on='product_id').round(3)\n",
        "\n",
        "def inventory_optimization_recommendations(data):\n",
        "    \"\"\"Provide inventory optimization recommendations\"\"\"\n",
        "    stock_risk = calculate_stockout_risk(data)\n",
        "    turnover = calculate_inventory_turnover(data)\n",
        "\n",
        "    # Merge analyses\n",
        "    inventory_analysis = stock_risk.merge(turnover, on='product_id')\n",
        "\n",
        "    # Fixed: Use proper string assignment with loc instead of np.select\n",
        "    inventory_analysis['recommendation'] = 'Monitor regularly'  # Default\n",
        "\n",
        "    # Assign recommendations using loc\n",
        "    high_risk_high_turnover = (inventory_analysis['stockout_risk'] == 'High') & (inventory_analysis['turnover_ratio'] > 2)\n",
        "    low_risk_low_turnover = (inventory_analysis['stockout_risk'] == 'Low') & (inventory_analysis['turnover_ratio'] < 1)\n",
        "    high_risk_low_turnover = (inventory_analysis['stockout_risk'] == 'High') & (inventory_analysis['turnover_ratio'] < 1)\n",
        "    low_risk_high_turnover = (inventory_analysis['stockout_risk'] == 'Low') & (inventory_analysis['turnover_ratio'] > 2)\n",
        "\n",
        "    inventory_analysis.loc[high_risk_high_turnover, 'recommendation'] = 'Increase stock - High demand product'\n",
        "    inventory_analysis.loc[low_risk_low_turnover, 'recommendation'] = 'Reduce stock - Slow moving product'\n",
        "    inventory_analysis.loc[high_risk_low_turnover, 'recommendation'] = 'Review product performance - High risk, low turnover'\n",
        "    inventory_analysis.loc[low_risk_high_turnover, 'recommendation'] = 'Optimal stock level maintained'\n",
        "\n",
        "    return inventory_analysis\n",
        "\n",
        "def promotional_effectiveness_analysis(data):\n",
        "    \"\"\"Analyze effectiveness of discounts and promotions\"\"\"\n",
        "    transactions = data['transactions']\n",
        "\n",
        "    promo_analysis = transactions.groupby('discount').agg({\n",
        "        'transaction_id': 'count',\n",
        "        'quantity': 'sum',\n",
        "        'customer_id': 'nunique'\n",
        "    }).reset_index()\n",
        "\n",
        "    promo_analysis.columns = ['discount', 'transactions_count', 'total_quantity', 'unique_customers']\n",
        "    promo_analysis['avg_quantity_per_transaction'] = promo_analysis['total_quantity'] / promo_analysis['transactions_count']\n",
        "\n",
        "    return promo_analysis\n",
        "\n",
        "def demand_forecasting_prep(data, days=30):\n",
        "    \"\"\"Prepare data for demand forecasting\"\"\"\n",
        "    daily_sales = data['transactions'].groupby(['date', 'product_id'])['quantity'].sum().reset_index()\n",
        "\n",
        "    # Create complete date-product grid\n",
        "    dates = pd.date_range(daily_sales['date'].min(), daily_sales['date'].max())\n",
        "    products = daily_sales['product_id'].unique()\n",
        "\n",
        "    # Create multi-index\n",
        "    idx = pd.MultiIndex.from_product([dates, products], names=['date', 'product_id'])\n",
        "    complete_grid = pd.DataFrame(index=idx).reset_index()\n",
        "\n",
        "    # Merge with actual sales\n",
        "    forecast_data = complete_grid.merge(daily_sales, on=['date', 'product_id'], how='left')\n",
        "    forecast_data['quantity'] = forecast_data['quantity'].fillna(0)\n",
        "\n",
        "    # Add time features\n",
        "    forecast_data['day_of_week'] = forecast_data['date'].dt.dayofweek\n",
        "    forecast_data['month'] = forecast_data['date'].dt.month\n",
        "    forecast_data['week'] = forecast_data['date'].dt.isocalendar().week\n",
        "\n",
        "    return forecast_data\n",
        "\n",
        "def abc_analysis(data):\n",
        "    \"\"\"Perform ABC analysis on products\"\"\"\n",
        "    sales_value = data['transactions'].merge(\n",
        "        data['products'][['product_id', 'selling_price']],\n",
        "        on='product_id'\n",
        "    )\n",
        "\n",
        "    sales_value['revenue'] = sales_value['quantity'] * sales_value['selling_price']\n",
        "\n",
        "    product_revenue = sales_value.groupby('product_id')['revenue'].sum().reset_index()\n",
        "    product_revenue = product_revenue.merge(data['products'][['product_id', 'product_name']], on='product_id')\n",
        "\n",
        "    # Sort by revenue\n",
        "    product_revenue = product_revenue.sort_values('revenue', ascending=False)\n",
        "    product_revenue['cumulative_revenue'] = product_revenue['revenue'].cumsum()\n",
        "    product_revenue['cumulative_percentage'] = (product_revenue['cumulative_revenue'] / product_revenue['revenue'].sum()) * 100\n",
        "\n",
        "    # Fixed: Use proper string assignment with loc instead of np.select\n",
        "    product_revenue['abc_class'] = 'C'  # Default\n",
        "\n",
        "    product_revenue.loc[product_revenue['cumulative_percentage'] <= 80, 'abc_class'] = 'A'\n",
        "    product_revenue.loc[(product_revenue['cumulative_percentage'] > 80) &\n",
        "                       (product_revenue['cumulative_percentage'] <= 95), 'abc_class'] = 'B'\n",
        "\n",
        "    return product_revenue\n",
        "\n",
        "def calculate_gross_margin_roi(data):\n",
        "    \"\"\"Calculate Gross Margin Return on Inventory Investment\"\"\"\n",
        "    inventory_data = data['inventory']\n",
        "    products = data['products']\n",
        "\n",
        "    # Calculate average inventory value\n",
        "    avg_inventory = inventory_data.merge(products[['product_id', 'cost_price']], on='product_id')\n",
        "    avg_inventory['inventory_value'] = avg_inventory['quantity_in_stock'] * avg_inventory['cost_price']\n",
        "    avg_inv_value = avg_inventory.groupby('product_id')['inventory_value'].mean().reset_index()\n",
        "\n",
        "    # Calculate gross profit\n",
        "    transactions = data['transactions'].merge(products[['product_id', 'cost_price', 'selling_price']], on='product_id')\n",
        "    transactions['gross_profit'] = transactions['quantity'] * (transactions['selling_price'] - transactions['cost_price'])\n",
        "    total_profit = transactions.groupby('product_id')['gross_profit'].sum().reset_index()\n",
        "\n",
        "    # Calculate GMROI\n",
        "    gmroi_data = avg_inv_value.merge(total_profit, on='product_id')\n",
        "    gmroi_data['gmroi'] = gmroi_data['gross_profit'] / gmroi_data['inventory_value']\n",
        "\n",
        "    return gmroi_data.merge(products[['product_id', 'product_name']], on='product_id').round(3)\n",
        "\n",
        "def customer_lifetime_value_analysis(data):\n",
        "    \"\"\"Calculate Customer Lifetime Value\"\"\"\n",
        "    transactions = data['transactions']\n",
        "    products = data['products']\n",
        "\n",
        "    # Merge data and calculate revenue\n",
        "    customer_transactions = transactions.merge(products[['product_id', 'selling_price']], on='product_id')\n",
        "    customer_transactions['revenue'] = customer_transactions['quantity'] * customer_transactions['selling_price']\n",
        "\n",
        "    # Calculate CLV metrics\n",
        "    clv_data = customer_transactions.groupby('customer_id').agg({\n",
        "        'revenue': 'sum',\n",
        "        'transaction_id': 'count',\n",
        "        'date': ['min', 'max']\n",
        "    }).reset_index()\n",
        "\n",
        "    clv_data.columns = ['customer_id', 'total_revenue', 'transaction_count', 'first_purchase', 'last_purchase']\n",
        "\n",
        "    max_date = customer_transactions['date'].max()\n",
        "    clv_data['customer_age_days'] = (max_date - clv_data['first_purchase']).dt.days\n",
        "    clv_data['avg_transaction_value'] = clv_data['total_revenue'] / clv_data['transaction_count']\n",
        "    clv_data['purchase_frequency'] = clv_data['transaction_count'] / (clv_data['customer_age_days'] / 30)  # per month\n",
        "\n",
        "    # Simple CLV calculation\n",
        "    clv_data['clv'] = clv_data['avg_transaction_value'] * clv_data['purchase_frequency'] * 12  # Annual CLV\n",
        "\n",
        "    return clv_data.round(2)\n",
        "\n",
        "def product_association_analysis(data):\n",
        "    \"\"\"Analyze product associations (which products are often bought together)\"\"\"\n",
        "    transactions = data['transactions']\n",
        "\n",
        "    # Create transaction baskets\n",
        "    transaction_baskets = transactions.groupby('transaction_id')['product_id'].apply(list).reset_index()\n",
        "\n",
        "    # Simple association analysis (for demonstration)\n",
        "    product_pairs = []\n",
        "    for basket in transaction_baskets['product_id']:\n",
        "        if len(basket) > 1:\n",
        "            for i in range(len(basket)):\n",
        "                for j in range(i + 1, len(basket)):\n",
        "                    product_pairs.append(tuple(sorted([basket[i], basket[j]])))\n",
        "\n",
        "    # Count frequency of pairs\n",
        "    if product_pairs:\n",
        "        pair_counts = pd.Series(product_pairs).value_counts().reset_index()\n",
        "        pair_counts.columns = ['product_pair', 'frequency']\n",
        "\n",
        "        # Split product pairs\n",
        "        pair_counts[['product_id_1', 'product_id_2']] = pd.DataFrame(pair_counts['product_pair'].tolist(), index=pair_counts.index)\n",
        "\n",
        "        return pair_counts.merge(data['products'][['product_id', 'product_name']],\n",
        "                               left_on='product_id_1', right_on='product_id').merge(\n",
        "                                   data['products'][['product_id', 'product_name']],\n",
        "                                   left_on='product_id_2', right_on='product_id',\n",
        "                                   suffixes=('_1', '_2')\n",
        "                               )[['product_name_1', 'product_name_2', 'frequency']]\n",
        "    else:\n",
        "        return pd.DataFrame(columns=['product_name_1', 'product_name_2', 'frequency'])\n",
        "\n",
        "def calculate_inventory_carrying_costs(data, carrying_rate=0.25):\n",
        "    \"\"\"Calculate inventory carrying costs\"\"\"\n",
        "    inventory = data['inventory']\n",
        "    products = data['products']\n",
        "\n",
        "    # Calculate average inventory value\n",
        "    inventory_value = inventory.merge(products[['product_id', 'cost_price']], on='product_id')\n",
        "    inventory_value['daily_value'] = inventory_value['quantity_in_stock'] * inventory_value['cost_price']\n",
        "\n",
        "    avg_inventory_value = inventory_value.groupby('product_id')['daily_value'].mean().reset_index()\n",
        "    avg_inventory_value['annual_carrying_cost'] = avg_inventory_value['daily_value'] * carrying_rate\n",
        "\n",
        "    total_carrying_cost = avg_inventory_value['annual_carrying_cost'].sum()\n",
        "\n",
        "    return {\n",
        "        'product_costs': avg_inventory_value.merge(products[['product_id', 'product_name']], on='product_id'),\n",
        "        'total_annual_carrying_cost': total_carrying_cost\n",
        "    }\n",
        "\n",
        "def sales_velocity_analysis(data):\n",
        "    \"\"\"Analyze sales velocity (how quickly products sell)\"\"\"\n",
        "    transactions = data['transactions']\n",
        "\n",
        "    sales_velocity = transactions.groupby('product_id').agg({\n",
        "        'quantity': 'sum',\n",
        "        'date': ['min', 'max', 'count']\n",
        "    }).reset_index()\n",
        "\n",
        "    sales_velocity.columns = ['product_id', 'total_quantity', 'first_sale', 'last_sale', 'transaction_count']\n",
        "\n",
        "    sales_velocity['sales_period_days'] = (sales_velocity['last_sale'] - sales_velocity['first_sale']).dt.days + 1\n",
        "    sales_velocity['daily_velocity'] = sales_velocity['total_quantity'] / sales_velocity['sales_period_days']\n",
        "    sales_velocity['transaction_velocity'] = sales_velocity['transaction_count'] / sales_velocity['sales_period_days']\n",
        "\n",
        "    return sales_velocity.merge(data['products'][['product_id', 'product_name']], on='product_id').round(3)\n",
        "\n",
        "def regional_demand_variability(data):\n",
        "    \"\"\"Analyze demand variability across regions\"\"\"\n",
        "    regional_data = data['transactions'].merge(\n",
        "        data['products'][['product_id', 'category']],\n",
        "        on='product_id'\n",
        "    )\n",
        "\n",
        "    variability = regional_data.groupby(['region', 'category'])['quantity'].agg([\n",
        "        'mean', 'std', 'count'\n",
        "    ]).reset_index()\n",
        "\n",
        "    variability['coefficient_of_variation'] = variability['std'] / variability['mean']\n",
        "\n",
        "    # Fixed: Use proper string assignment\n",
        "    variability['demand_stability'] = 'Volatile'  # Default\n",
        "    variability.loc[variability['coefficient_of_variation'] < 0.5, 'demand_stability'] = 'Stable'\n",
        "    variability.loc[(variability['coefficient_of_variation'] >= 0.5) &\n",
        "                   (variability['coefficient_of_variation'] < 1.0), 'demand_stability'] = 'Moderate'\n",
        "\n",
        "    return variability.round(3)\n",
        "\n",
        "def profitability_by_time_period(data):\n",
        "    \"\"\"Analyze profitability by different time periods\"\"\"\n",
        "    transactions = data['transactions']\n",
        "    products = data['products']\n",
        "\n",
        "    merged_data = transactions.merge(products[['product_id', 'cost_price', 'selling_price']], on='product_id')\n",
        "    merged_data['profit'] = merged_data['quantity'] * (merged_data['selling_price'] - merged_data['cost_price'])\n",
        "\n",
        "    # By day of week\n",
        "    merged_data['day_of_week'] = merged_data['date'].dt.day_name()\n",
        "    profit_by_dow = merged_data.groupby('day_of_week')['profit'].sum().reset_index()\n",
        "\n",
        "    # By month\n",
        "    merged_data['month'] = merged_data['date'].dt.month_name()\n",
        "    profit_by_month = merged_data.groupby('month')['profit'].sum().reset_index()\n",
        "\n",
        "    # By week\n",
        "    merged_data['week'] = merged_data['date'].dt.isocalendar().week\n",
        "    profit_by_week = merged_data.groupby('week')['profit'].sum().reset_index()\n",
        "\n",
        "    return {\n",
        "        'by_day_of_week': profit_by_dow,\n",
        "        'by_month': profit_by_month,\n",
        "        'by_week': profit_by_week\n",
        "    }\n",
        "\n",
        "def inventory_aging_analysis(data):\n",
        "    \"\"\"Analyze inventory aging and identify stale stock\"\"\"\n",
        "    inventory = data['inventory']\n",
        "    products = data['products']\n",
        "\n",
        "    # Get latest inventory snapshot\n",
        "    latest_date = inventory['date'].max()\n",
        "    latest_inventory = inventory[inventory['date'] == latest_date]\n",
        "\n",
        "    # Calculate days since last sale (simplified)\n",
        "    last_sales = inventory[inventory['quantity_sold'] > 0].groupby('product_id')['date'].max().reset_index()\n",
        "    last_sales.columns = ['product_id', 'last_sale_date']\n",
        "\n",
        "    aging_analysis = latest_inventory.merge(last_sales, on='product_id', how='left')\n",
        "    aging_analysis['days_since_last_sale'] = (latest_date - aging_analysis['last_sale_date']).dt.days\n",
        "\n",
        "    # Fixed: Use proper string assignment\n",
        "    aging_analysis['aging_category'] = 'Fresh (<30 days)'  # Default\n",
        "    aging_analysis.loc[aging_analysis['days_since_last_sale'] > 60, 'aging_category'] = 'Stale (>60 days)'\n",
        "    aging_analysis.loc[(aging_analysis['days_since_last_sale'] > 30) &\n",
        "                      (aging_analysis['days_since_last_sale'] <= 60), 'aging_category'] = 'Aging (30-60 days)'\n",
        "\n",
        "    return aging_analysis.merge(products[['product_id', 'product_name']], on='product_id')\n",
        "\n",
        "def optimal_order_quantity_calculation(data, ordering_cost=50, holding_rate=0.25):\n",
        "    \"\"\"Calculate Economic Order Quantity (EOQ) for products\"\"\"\n",
        "    products = data['products']\n",
        "    inventory = data['inventory']\n",
        "\n",
        "    # Calculate annual demand and holding cost\n",
        "    annual_demand = inventory.groupby('product_id')['quantity_sold'].sum() * 12/3  # Annualize 3 months data\n",
        "    holding_cost = products.set_index('product_id')['cost_price'] * holding_rate\n",
        "\n",
        "    eoq_data = pd.DataFrame({\n",
        "        'annual_demand': annual_demand,\n",
        "        'holding_cost': holding_cost\n",
        "    }).reset_index()\n",
        "\n",
        "    # EOQ formula: sqrt((2 * demand * ordering_cost) / holding_cost)\n",
        "    eoq_data['eoq'] = np.sqrt((2 * eoq_data['annual_demand'] * ordering_cost) / eoq_data['holding_cost'])\n",
        "    eoq_data['eoq'] = eoq_data['eoq'].round(0)\n",
        "\n",
        "    return eoq_data.merge(products[['product_id', 'product_name']], on='product_id')\n",
        "\n",
        "def product_portfolio_analysis(data):\n",
        "    \"\"\"Analyze product portfolio using BCG matrix (Stars, Cash Cows, Question Marks, Dogs)\"\"\"\n",
        "    growth_data = sales_velocity_analysis(data)\n",
        "    margin_data = calculate_profit_margins(data)\n",
        "\n",
        "    portfolio = growth_data.merge(margin_data, on='product_id')\n",
        "\n",
        "    # Calculate relative market share and growth\n",
        "    avg_growth = portfolio['daily_velocity'].mean()\n",
        "    avg_margin = portfolio['profit_margin_pct'].mean()\n",
        "\n",
        "    portfolio['relative_growth'] = portfolio['daily_velocity'] / avg_growth\n",
        "    portfolio['relative_margin'] = portfolio['profit_margin_pct'] / avg_margin\n",
        "\n",
        "    # Fixed: Use proper string assignment with loc\n",
        "    portfolio['bcg_category'] = 'Dog'  # Default\n",
        "\n",
        "    portfolio.loc[(portfolio['relative_growth'] >= 1) & (portfolio['relative_margin'] >= 1), 'bcg_category'] = 'Star'\n",
        "    portfolio.loc[(portfolio['relative_growth'] < 1) & (portfolio['relative_margin'] >= 1), 'bcg_category'] = 'Cash Cow'\n",
        "    portfolio.loc[(portfolio['relative_growth'] >= 1) & (portfolio['relative_margin'] < 1), 'bcg_category'] = 'Question Mark'\n",
        "\n",
        "    return portfolio[['product_id', 'product_name_x', 'daily_velocity', 'profit_margin_pct',\n",
        "                     'relative_growth', 'relative_margin', 'bcg_category']].rename(\n",
        "                         columns={'product_name_x': 'product_name'})\n",
        "\n",
        "def generate_distributor_insights_report(data):\n",
        "    \"\"\"Generate comprehensive insights report for the distributor\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"GROCERY DISTRIBUTOR COMPREHENSIVE INSIGHTS REPORT\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Key metrics\n",
        "    total_products = len(data['products'])\n",
        "    total_transactions = len(data['transactions'])\n",
        "    total_customers = data['transactions']['customer_id'].nunique()\n",
        "\n",
        "    print(f\"\\n KEY METRICS:\")\n",
        "    print(f\"Total Products: {total_products}\")\n",
        "    print(f\"Total Transactions: {total_transactions}\")\n",
        "    print(f\"Total Customers: {total_customers}\")\n",
        "\n",
        "    # Top performing products\n",
        "    profit_margins = calculate_profit_margins(data)\n",
        "    top_products = profit_margins.nlargest(5, 'profit')\n",
        "\n",
        "    print(f\"\\n TOP 5 PRODUCTS BY PROFIT:\")\n",
        "    for _, product in top_products.iterrows():\n",
        "        print(f\"  {product['product_name']}: ${product['profit']:.2f}\")\n",
        "\n",
        "    # Inventory risk\n",
        "    stock_risk = calculate_stockout_risk(data)\n",
        "    high_risk = stock_risk[stock_risk['stockout_risk'] == 'High']\n",
        "\n",
        "    print(f\"\\n  HIGH STOCKOUT RISK PRODUCTS ({len(high_risk)}):\")\n",
        "    for _, product in high_risk.iterrows():\n",
        "        print(f\"  {product['product_name']} - {product['days_of_supply']:.1f} days supply\")\n",
        "\n",
        "    # Customer segments\n",
        "    segments = customer_segmentation_analysis(data)\n",
        "    segment_counts = segments['segment'].value_counts()\n",
        "\n",
        "    print(f\"\\n CUSTOMER SEGMENTS:\")\n",
        "    for segment, count in segment_counts.items():\n",
        "        print(f\"  {segment}: {count} customers\")\n",
        "\n",
        "    # Regional performance\n",
        "    regional = regional_sales_analysis(data)\n",
        "    best_region = regional.loc[regional['total_revenue'].idxmax()]\n",
        "\n",
        "    print(f\"\\n REGIONAL PERFORMANCE:\")\n",
        "    print(f\"  Best Performing Region: {best_region['region']} (${best_region['total_revenue']:.2f})\")\n",
        "\n",
        "    return {\n",
        "        'key_metrics': {\n",
        "            'total_products': total_products,\n",
        "            'total_transactions': total_transactions,\n",
        "            'total_customers': total_customers\n",
        "        },\n",
        "        'top_products': top_products,\n",
        "        'high_risk_products': high_risk,\n",
        "        'customer_segments': segment_counts,\n",
        "        'best_region': best_region\n",
        "    }\n",
        "\n",
        "# ==================== MAIN EXECUTION ====================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to demonstrate all analyses\"\"\"\n",
        "    print(\"Creating Grocery Distributor Dataset...\")\n",
        "    data = create_grocery_distributor_data()\n",
        "\n",
        "    print(\"Dataset created successfully!\")\n",
        "    print(f\"Products: {len(data['products'])}\")\n",
        "    print(f\"Inventory Records: {len(data['inventory'])}\")\n",
        "    print(f\"Transactions: {len(data['transactions'])}\")\n",
        "    print(f\"Suppliers: {len(data['suppliers'])}\")\n",
        "\n",
        "    # Demonstrate key analyses\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"RUNNING ADVANCED ANALYSES\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "       # 2. Profit Margins\n",
        "    print(\"\\n2.  Profit Margin Analysis:\")\n",
        "    margins = calculate_profit_margins(data)\n",
        "    print(margins.head())\n",
        "\n",
        "    # 3. Stockout Risk\n",
        "    print(\"\\n3.  Stockout Risk Analysis:\")\n",
        "    stock_risk = calculate_stockout_risk(data)\n",
        "    print(stock_risk.head())\n",
        "\n",
        "    # 4. Customer Segmentation\n",
        "    print(\"\\n4.  Customer Segmentation:\")\n",
        "    segments = customer_segmentation_analysis(data)\n",
        "    print(segments.head())\n",
        "\n",
        "    # 5. ABC Analysis\n",
        "    print(\"\\n5.  ABC Analysis:\")\n",
        "    abc = abc_analysis(data)\n",
        "    print(abc.head())\n",
        "\n",
        "    # 6. Generate Comprehensive Report\n",
        "    print(\"\\n6. Generating Comprehensive Insights Report...\")\n",
        "    insights = generate_distributor_insights_report(data)\n",
        "\n",
        "\n",
        "    return data\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    grocery_data = main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VP2XhffVuajb",
        "outputId": "8b8ab520-9d0d-4b45-bf06-6d5a3c0332e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Grocery Distributor Dataset...\n",
            "Dataset created successfully!\n",
            "Products: 20\n",
            "Inventory Records: 1820\n",
            "Transactions: 1000\n",
            "Suppliers: 5\n",
            "\n",
            "==================================================\n",
            "RUNNING ADVANCED ANALYSES\n",
            "==================================================\n",
            "\n",
            "2.  Profit Margin Analysis:\n",
            "   product_id product_name  revenue     cost   profit  profit_margin_pct\n",
            "0           1         Milk  1339.05  5401.40 -4062.35            -303.38\n",
            "1           2        Bread  3172.54   477.40  2695.14              84.95\n",
            "2           3         Eggs  3664.44   641.52  3022.92              82.49\n",
            "3           4         Rice  8080.32  3807.60  4272.72              52.88\n",
            "4           5        Pasta  8095.15  3333.00  4762.15              58.83\n",
            "\n",
            "3.  Stockout Risk Analysis:\n",
            "   product_id product_name  quantity_in_stock  avg_daily_sales  \\\n",
            "0           1         Milk                175        48.593407   \n",
            "1           2        Bread                459        53.351648   \n",
            "2           3         Eggs                398        50.725275   \n",
            "3           4         Rice                166        46.582418   \n",
            "4           5        Pasta                 31        50.241758   \n",
            "\n",
            "   days_of_supply stockout_risk  safety_stock  reorder_point  \n",
            "0        3.601312        Medium            89             54  \n",
            "1        8.603296           Low           131             54  \n",
            "2        7.846187           Low           160             52  \n",
            "3        3.563576        Medium           102             24  \n",
            "4        0.617017          High            73             60  \n",
            "\n",
            "4.  Customer Segmentation:\n",
            "   customer_id  total_orders  total_quantity first_purchase last_purchase  \\\n",
            "0            1            20             230     2024-01-05    2024-03-18   \n",
            "1            2            26             279     2024-01-01    2024-03-31   \n",
            "2            3            32             302     2024-01-01    2024-03-29   \n",
            "3            4            17             152     2024-01-01    2024-03-23   \n",
            "4            5            21             235     2024-01-06    2024-03-29   \n",
            "\n",
            "   recency  frequency segment  \n",
            "0       13         20   Loyal  \n",
            "1        0         26   Loyal  \n",
            "2        2         32   Loyal  \n",
            "3        8         17   Loyal  \n",
            "4        2         21   Loyal  \n",
            "\n",
            "5.  ABC Analysis:\n",
            "    product_id   revenue product_name  cumulative_revenue  \\\n",
            "17          18  12144.51       Cereal            12144.51   \n",
            "18          19  11650.06       Coffee            23794.57   \n",
            "9           10  11563.89      Bananas            35358.46   \n",
            "14          15  10343.08       Cheese            45701.54   \n",
            "12          13   9005.88     Potatoes            54707.42   \n",
            "\n",
            "    cumulative_percentage abc_class  \n",
            "17               9.685072         A  \n",
            "18              18.975827         A  \n",
            "9               28.197864         A  \n",
            "14              36.446321         A  \n",
            "12              43.628381         A  \n",
            "\n",
            "6. Generating Comprehensive Insights Report...\n",
            "============================================================\n",
            "GROCERY DISTRIBUTOR COMPREHENSIVE INSIGHTS REPORT\n",
            "============================================================\n",
            "\n",
            " KEY METRICS:\n",
            "Total Products: 20\n",
            "Total Transactions: 1000\n",
            "Total Customers: 50\n",
            "\n",
            " TOP 5 PRODUCTS BY PROFIT:\n",
            "  Chicken: $7413.80\n",
            "  Coffee: $6120.48\n",
            "  Bananas: $5796.87\n",
            "  Cheese: $5251.40\n",
            "  Butter: $4910.40\n",
            "\n",
            "  HIGH STOCKOUT RISK PRODUCTS (5):\n",
            "  Pasta - 0.6 days supply\n",
            "  Chicken - 3.0 days supply\n",
            "  Beef - 1.7 days supply\n",
            "  Yogurt - 1.7 days supply\n",
            "  Cereal - 2.7 days supply\n",
            "\n",
            " CUSTOMER SEGMENTS:\n",
            "  Loyal: 50 customers\n",
            "\n",
            " REGIONAL PERFORMANCE:\n",
            "  Best Performing Region: South ($34199.43)\n",
            "\n",
            "7. Additional analyses available:\n",
            "   - Seasonal Demand Analysis\n",
            "   - Supplier Performance Analysis\n",
            "   - Price Elasticity Analysis\n",
            "   - Inventory Optimization Recommendations\n",
            "   - And many more...\n"
          ]
        }
      ]
    }
  ]
}